{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x , y = iris.data , iris.target\n",
    "x_train , x_test , y_train , y_test = train_test_split( x , y , test_size= 0.25 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train , y_train)\n",
    "y_pred = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING THE ACCURACY OF THE MODEL ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationEvaluation:\n",
    "    \n",
    "    def accuracy( self , y_pred , y_test):\n",
    "        return metrics.accuracy_score(y_test , y_pred)\n",
    "    \n",
    "    def precision(self , y_pred , y_test):\n",
    "        return metrics.precision_score(y_test , y_pred)\n",
    "    \n",
    "    def recall(self , y_pred , y_test):\n",
    "        return metrics.recall_score(y_test , y_pred)\n",
    "    \n",
    "    def f1(self , y_pred , y_test):\n",
    "        return metrics.f1_score(y_test , y_pred)\n",
    "    \n",
    "    def auc(self , y_pred , y_test):\n",
    "        return metrics.roc_auc_score(y_test , y_pred)\n",
    "    \n",
    "    def confusion_matrix(self , y_pred , y_test):\n",
    "        return metrics.confusion_matrix(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = ClassificationEvaluation()\n",
    "eval.accuracy(y_pred , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for evaluation metrics of regression problems.\n",
    "class RegressionEvaluation:\n",
    "\n",
    "    # Returns the mean squared error between the true and predicted values.\n",
    "    def mean_squared_error(self, y_true, y_pred):\n",
    "        return metrics.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Returns the mean squared error between the true and predicted values.\n",
    "    def mean_squared_error_with_std(self, y_true, y_pred):\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        errors = np.square(y_true-y_pred)\n",
    "        mse = errors.mean()\n",
    "        std = errors.std()\n",
    "        return mse.mean(), std.mean()\n",
    "\n",
    "    # Returns the mean absolute error between the true and predicted values.\n",
    "    def mean_absolute_error(self, y_true, y_pred):\n",
    "        return metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Return the mean absolute error between the true and predicted values\n",
    "    # as well as its standard deviation.\n",
    "    def mean_absolute_error_with_std(self, y_true, y_pred):\n",
    "        errors = np.absolute((y_pred - y_true))\n",
    "        return errors.mean(), errors.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
