{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data['data'] , columns= data['feature_names'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                            FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s not recommended to perform feature selection before splitting your data into training and test sets. Here’s why:\n",
    "\n",
    "When you perform feature selection before splitting the data, you’re using information from the entire dataset to select features. This includes information from the test set. This is a form of data leakage, where information from outside the training dataset is used to create the model. This can lead to overly optimistic performance estimates.\n",
    "\n",
    "To avoid this, you should first split your data into training and test sets, and then perform feature selection using only the training data. This ensures that the feature selection process doesn’t have access to any information from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEARSON CO-EFFICIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worst concave points', 'mean concave points', 'worst perimeter', 'worst radius', 'mean perimeter', 'worst area', 'mean radius', 'mean area', 'mean concavity']\n",
      "\n",
      "worst concave points    0.788885\n",
      "mean concave points     0.778115\n",
      "worst perimeter         0.774998\n",
      "worst radius            0.766527\n",
      "mean perimeter          0.731859\n",
      "worst area              0.722875\n",
      "mean radius             0.718073\n",
      "mean area               0.695171\n",
      "mean concavity          0.683262\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class pearson_coefficient:\n",
    "    \n",
    "    def __init__(self , max_features):\n",
    "        self.max_features = max_features\n",
    "        \n",
    "    def pearsons_corr(self, x_train, y_train):\n",
    "        df = pd.DataFrame(x_train)\n",
    "        df['target'] = y_train\n",
    "        correlations = df.corr()['target'].drop('target') #finds the corr of all columns to the target variable \n",
    "        \n",
    "        #using abs coz -> in many cases we are interested in the magnitude (value) instead of direction ( pos / negative)\n",
    "        sorted_corr = correlations.abs().sort_values(ascending = False) \n",
    "        selected_features = sorted_corr.index[: self.max_features].tolist()\n",
    "        return selected_features[: self.max_features] , sorted_corr[: self.max_features]\n",
    "\n",
    "# Split your data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the class and call the method with the training data\n",
    "instance = pearson_coefficient(max_features= 9 )\n",
    "selected_features , sorted_corr = instance.pearsons_corr(x_train = x_train , y_train = y_train)\n",
    "\n",
    "print(f\"{selected_features}\\n\\n{sorted_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORWARD SELECTION ( Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs forward feature selection. It starts with no features and iteratively adds the feature that gives the best performance improvement when added to the already selected features. The performance is measured using the accuracy of a decision tree classifier. The function returns the selected features in the order they were added, along with their corresponding scores. The print statement inside the loop provides a step-by-step log of which feature is selected at each step and its corresponding score. This can be helpful for understanding how the feature selection process is progressing. Note that you’ll need to import the necessary libraries (DecisionTreeClassifier and accuracy_score from sklearn) for this code to work. Also, this code assumes that X_train, X_test, y_train, and y_test are defined elsewhere in your code and are passed as arguments to the forward_selection method. These should be your training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORWARD FEATURE SELECTION :\n",
    "\n",
    "This function performs forward feature selection. It starts with no features and iteratively adds the feature that gives the best performance improvement when added to the already selected features. The performance is measured using the accuracy of a decision tree classifier. The function returns the selected features in the order they were added, along with their corresponding scores. The print statement inside the loop provides a step-by-step log of which feature is selected at each step and its corresponding score. This can be helpful for understanding how the feature selection process is progressing. Note that you’ll need to import the necessary libraries (DecisionTreeClassifier and accuracy_score from sklearn) for this code to work. Also, this code assumes that X_train, X_test, y_train, and y_test are defined elsewhere in your code and are passed as arguments to the forward_selection method. These should be your training and testing datasets.\n",
    "\n",
    "\n",
    "Empty Set of Features --> {Feature 1} --> {Feature 1, Feature 2} --> {Feature 1, Feature 2, Feature 3} --> ... --> Best Set of Features\n",
    "\n",
    ">> Sure, let’s consider a simple dataset with three features (F1, F2, F3) and a binary target variable (T).\n",
    "\n",
    "    > Iteration 1: We start with no features. We then fit the model with each feature (F1, F2, F3) and calculate the accuracy. Let’s say F1 gives the best accuracy. So, we select F1.\n",
    "\n",
    "    > Iteration 2: We now have F1 in our model. We then try adding each of the remaining features (F2, F3) to F1 and fit the model. Let’s say adding F2 gives the best accuracy. So, we select F2.\n",
    "\n",
    "    > Iteration 3: We now have F1 and F2 in our model. We then try adding the remaining feature (F3) to F1 and F2 and fit the model. If adding F3 improves the accuracy, we select F3, otherwise, we stop here.\n",
    "\n",
    "If F3 does not improve the model, our final set of selected features would just be {F1, F2}. This set of features is expected to give us the best predictive performance according to the forward feature selection process.\n",
    "\n",
    "The goal of forward feature selection is to find the smallest set of features that gives the best predictive performance. The advantage of this method is that it can significantly reduce the dimensionality of the problem, making the model simpler, faster, and less prone to overfitting\n",
    "\n",
    "The downside is that it can be computationally expensive, especially if the number of features is large, as it requires fitting a model for each subset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 : worst area with score 0.9210526315789473\n",
      "Feature 2 : worst fractal dimension with score 0.9824561403508771\n",
      "Feature 3 : concave points error with score 0.9912280701754386\n",
      "Feature 4 : smoothness error with score 0.9912280701754386\n",
      "Feature 5 : worst smoothness with score 1.0\n",
      "Feature 6 : mean fractal dimension with score 1.0\n",
      "Feature 7 : symmetry error with score 1.0\n",
      "Feature 8 : mean smoothness with score 1.0\n",
      "Feature 9 : worst radius with score 1.0\n",
      "Feature 10 : fractal dimension error with score 1.0\n",
      "Feature 11 : mean symmetry with score 1.0\n",
      "Feature 12 : mean texture with score 1.0\n",
      "Selected features: ['worst area', 'worst fractal dimension', 'concave points error', 'smoothness error', 'worst smoothness', 'mean fractal dimension', 'symmetry error', 'mean smoothness', 'worst radius', 'fractal dimension error', 'mean symmetry', 'mean texture']\n",
      "Ordered scores: [0.9210526315789473, 0.9824561403508771, 0.9912280701754386, 0.9912280701754386, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FeatureSelector:\n",
    "    \n",
    "    #initializing the class with max_features \n",
    "    def __init__(self , max_features):\n",
    "        self.max_features = max_features\n",
    "        \n",
    "    #define forward selection method \n",
    "    def forward_selection(self , x_train , y_train , x_test , y_test):\n",
    "        \n",
    "        #initializing the lists for storing the selected features and scores \n",
    "        selected_features = []\n",
    "        ordered_scores = []\n",
    "        \n",
    "        #iterate over the range of maximum features\n",
    "        for i in range(self.max_features):\n",
    "            features_left = list(set(x_train.columns) - set(selected_features))\n",
    "            \n",
    "            #initialize the best score to 0 and best feature to empty string \n",
    "            best_score = 0\n",
    "            best_feature = ''\n",
    "            \n",
    "            #iterate over each feature left to be selected \n",
    "            for feature in features_left:\n",
    "                #create a temporary list of features and append the current feature to it \n",
    "                temp_selected_features = selected_features + [feature]\n",
    "                \n",
    "                #train a decision tree classifier on the training data with temporary selected features\n",
    "                classifier = DecisionTreeClassifier().fit(x_train[temp_selected_features], y_train)\n",
    "                \n",
    "                #predict the test data and calculcate the accuracy \n",
    "                y_pred = classifier.predict(x_test[temp_selected_features])\n",
    "                score = accuracy_score(y_test , y_pred)\n",
    "                \n",
    "                #if current score is better than best score update the best score and best feature\n",
    "                if score > best_score:\n",
    "                    best_score = score \n",
    "                    best_feature = feature\n",
    "                    \n",
    "            #append the best feature and its score to respective lists \n",
    "            selected_features.append(best_feature)\n",
    "            ordered_scores.append(best_score)\n",
    "            \n",
    "            print(f\"Feature {i+1} : {best_feature} with score {best_score}\")\n",
    "        \n",
    "        return selected_features , ordered_scores\n",
    "    \n",
    "#test train split of the data \n",
    "x = df\n",
    "x_train , x_test , y_train , y_test = train_test_split( df , data.target , test_size= 0.2 , random_state= 42)\n",
    "\n",
    "fs = FeatureSelector(max_features= 12)\n",
    "selected_features , ordered_scores = fs.forward_selection(x_train , y_train , x_test , y_test)\n",
    "\n",
    "# Print the selected features and their scores\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(\"Ordered scores:\", ordered_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
